{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Laboratorio #4 - Machine Learning Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stefanie M. Alvarez Pérez, 20002045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, Binarizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from feature_engine.imputation import(\n",
    "    AddMissingIndicator,\n",
    "    MeanMedianImputer,\n",
    "    CategoricalImputer\n",
    ")\n",
    "\n",
    "from feature_engine.encoding import (\n",
    "    RareLabelEncoder,\n",
    "    OrdinalEncoder\n",
    ")\n",
    "\n",
    "from feature_engine.transformation import LogTransformer\n",
    "\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_preprocessors as mypp #nuestra librería"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cast de Variable Pclass\n",
    "data['Pclass'] = data['Pclass'].astype('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((623, 7), (268, 7))"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.drop(['PassengerId', 'Ticket', 'Name', 'Cabin', 'Fare'], axis=1),\n",
    "        data['Survived'],\n",
    "        test_size=0.3,\n",
    "        random_state=2022)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 7)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transformación al Target\n",
    "#y_train = np.log(y_train)\n",
    "#y_test = np.log(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = pd.read_csv(\"test.csv\")\n",
    "X_test = X_test[FEATURES]\n",
    "#X_test['Pclass'] = X_test['Pclass'].astype('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 5)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración del Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables categoricas con NA\n",
    "CATEGORICAL_VARS_WITH_NA_FREQUENT = ['Embarked']\n",
    "\n",
    "#Variable categoricas con NA pero indicador de Missing\n",
    "CATEGORICAL_VARS_WITH_NA_MISSING = []\n",
    "\n",
    "\n",
    "#Variables numéricas con NA\n",
    "NUMERICAL_VARS_WITH_NA = ['Age']\n",
    "\n",
    "\n",
    "#Variables de temporalidad\n",
    "#TEMPORAL_VARS = ['']\n",
    "#REF_VAR = \"\"\n",
    "\n",
    "#Varaibles que vamos a tirar\n",
    "DROP_FEATURES = []\n",
    "\n",
    "#Varibles para transformación logarítmica\n",
    "NUMERICALS_LOG_VARS = [] #\"Fare\"\n",
    "\n",
    "#Variables para binarización por sesgo fuerte\n",
    "BINARIZE_VARS = []\n",
    "\n",
    "#Variables para hacer mapeo categorico por codificación ordinal\n",
    "Lista_Sex = ['Sex']\n",
    "Lista_E = ['Embarked']\n",
    "\n",
    "#Variables categoricas a codificar sin ordinalidad\n",
    "#CATEGORICAL_VARS = []\n",
    "\n",
    "#Mapeos de variables categoricas\n",
    "Diccio_Sex = {'female':1, 'male':2, '3':3, 'Missing':0, 'NA':0, 'NaN':0}\n",
    "Diccio_E = {'C':1, 'Q':2, 'S':3, 'Missing':0, 'NA':0, 'NaN':0}\n",
    "\n",
    "#Variables seleccionadas según análisis de Lasso\n",
    "FEATURES = [\n",
    "    'Pclass', \n",
    "    'Sex', \n",
    "    'Age', \n",
    "    'SibSp', \n",
    "    'Embarked',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(623, 5)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Selección de variables para entrenamiento\n",
    "X_train = X_train[FEATURES]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning PipeLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "Titanic_pipeline = Pipeline([\n",
    "    \n",
    "    #============= IMPUTACIONES ===================#\n",
    "    \n",
    "    #1. Imputación de varaibles categoricas\n",
    "    ('missing_imputation', \n",
    "         CategoricalImputer(imputation_method='missing', variables=CATEGORICAL_VARS_WITH_NA_MISSING)\n",
    "    ),\n",
    "    \n",
    "    #2. Imputación de variables categoricas con NA basado en frequiencia.\n",
    "    ('frequent_imputation', \n",
    "         CategoricalImputer(imputation_method='frequent', variables=CATEGORICAL_VARS_WITH_NA_FREQUENT)\n",
    "    ),\n",
    "    \n",
    "    #3. Indicamos Faltante en variables numéricas para imputar\n",
    "    ('missing_indicator', AddMissingIndicator(variables=NUMERICAL_VARS_WITH_NA)),\n",
    "    \n",
    "    #4. Imputación de mediana para variables categoricas\n",
    "    ('mean_imputation', MeanMedianImputer(\n",
    "        imputation_method='mean', variables=NUMERICAL_VARS_WITH_NA)\n",
    "    ),\n",
    "    \n",
    "    #============= VARIABLES TEMPORALES ==================\n",
    "    \n",
    "    #5. Tratamiento de variables temporales\n",
    "    #('eslapsed_time', mypp.TremporalVariableTransformer(\n",
    "    #   variables=TEMPORAL_VARS, reference_variable=REF_VAR)\n",
    "    #),\n",
    "    \n",
    "    #6. Drop de variables\n",
    "    #('drop_features', DropFeatures(features_to_drop=DROP_FEATURES)),\n",
    "    \n",
    "    #============= TRANSFORMACIÓN DE VARIABLES NUMÉRICAS =============\n",
    "    \n",
    "    #7. Transformación logaritmica\n",
    "    #('log', LogTransformer(variables=NUMERICALS_LOG_VARS)),\n",
    "    \n",
    "    #8. Binarización de Variables con Sesgo Fuerte\n",
    "    ('binarizer', SklearnTransformerWrapper(\n",
    "        transformer=Binarizer(threshold=0), variables=BINARIZE_VARS)\n",
    "    ),\n",
    "    \n",
    "    #=============== CODIFICACION DE VARIABLES CATEGORICAS ORDINALES ==============\n",
    "    ('mapper_sex', mypp.Mapper(variables=Lista_Sex, mappings=Diccio_Sex)),\n",
    "    \n",
    "    ('mapper_Embarked', mypp.Mapper(\n",
    "        variables=Lista_E, mappings=Diccio_E)),\n",
    "    \n",
    "    \n",
    "    #============ CODIFICACION DE VARIABLES CATEGORICAS NOMINALES ============\n",
    "    \n",
    "    #('rare_label_encoder', RareLabelEncoder(\n",
    "        #tol=0.01, n_categories=1, variables=CATEGORICAL_VARS)),\n",
    "    \n",
    "    #('categorical_encoder', OrdinalEncoder(\n",
    "        #encoding_method='ordered', variables=CATEGORICAL_VARS)),\n",
    "    \n",
    "    #=========== SCALER ==============\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    \n",
    "    #=========== ENTRENAMIENTO DEL MODELO ============\n",
    "    ('Lasso', Lasso(alpha=0.01, random_state=2022)),\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('missing_imputation', CategoricalImputer(variables=[])),\n",
       "                ('frequent_imputation',\n",
       "                 CategoricalImputer(imputation_method='frequent',\n",
       "                                    variables=['Embarked'])),\n",
       "                ('missing_indicator', AddMissingIndicator(variables=['Age'])),\n",
       "                ('mean_imputation',\n",
       "                 MeanMedianImputer(imputation_method='mean',\n",
       "                                   variables=['Age'])),\n",
       "                ('binarizer',\n",
       "                 SklearnTransformerWrapper(transformer=Binarizer(threshold=0),\n",
       "                                           variables=[])),\n",
       "                ('mapper_sex',\n",
       "                 Mapper(mappings={'3': 3, 'Missing': 0, 'NA': 0, 'NaN': 0,\n",
       "                                  'female': 1, 'male': 2},\n",
       "                        variables=['Sex'])),\n",
       "                ('mapper_Embarked',\n",
       "                 Mapper(mappings={'C': 1, 'Missing': 0, 'NA': 0, 'NaN': 0,\n",
       "                                  'Q': 2, 'S': 3},\n",
       "                        variables=['Embarked'])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('Lasso', Lasso(alpha=0.01, random_state=2022))])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Titanic_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('missing_imputation', CategoricalImputer(variables=[])),\n",
       "                ('frequent_imputation',\n",
       "                 CategoricalImputer(imputation_method='frequent',\n",
       "                                    variables=['Embarked'])),\n",
       "                ('missing_indicator', AddMissingIndicator(variables=['Age'])),\n",
       "                ('mean_imputation',\n",
       "                 MeanMedianImputer(imputation_method='mean',\n",
       "                                   variables=['Age'])),\n",
       "                ('binarizer',\n",
       "                 SklearnTransformerWrapper(transformer=Binarizer(threshold=0),\n",
       "                                           variables=[])),\n",
       "                ('mapper_sex',\n",
       "                 Mapper(mappings={'3': 3, 'Missing': 0, 'NA': 0, 'NaN': 0,\n",
       "                                  'female': 1, 'male': 2},\n",
       "                        variables=['Sex'])),\n",
       "                ('mapper_Embarked',\n",
       "                 Mapper(mappings={'C': 1, 'Missing': 0, 'NA': 0, 'NaN': 0,\n",
       "                                  'Q': 2, 'S': 3},\n",
       "                        variables=['Embarked'])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('Lasso', Lasso(alpha=0.01, random_state=2022))])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Titanic_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = Titanic_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21489429, 0.21489429, 0.71227322, 0.17896185, 0.17896185,\n",
       "       0.74078496, 0.21489429, 0.74078496, 0.17896185, 0.21489429,\n",
       "       0.21489429, 0.72652909, 0.74078496, 0.21489429, 0.21489429,\n",
       "       0.75504083, 0.21489429, 0.21489429, 0.21489429, 0.71227322,\n",
       "       0.24340603, 0.21489429, 0.24340603, 0.71227322, 0.70485252,\n",
       "       0.69059665, 0.20747359, 0.21489429, 0.17896185, 0.74078496,\n",
       "       0.19321772, 0.19321772, 0.24340603, 0.22915016, 0.21489429,\n",
       "       0.71227322, 0.21489429, 0.71227322, 0.74078496, 0.71227322,\n",
       "       0.67634078, 0.21489429, 0.67634078, 0.21489429, 0.21489429,\n",
       "       0.21489429, 0.24340603, 0.21489429, 0.21489429, 0.74078496,\n",
       "       0.21489429, 0.72652909, 0.67634078, 0.21489429, 0.21489429,\n",
       "       0.21489429, 0.21489429, 0.21489429, 0.71227322, 0.21489429,\n",
       "       0.71227322, 0.21489429, 0.71227322, 0.21489429, 0.21489429,\n",
       "       0.21489429, 0.21489429, 0.69059665, 0.21489429, 0.71227322,\n",
       "       0.21489429, 0.71227322, 0.17896185, 0.69059665, 0.71227322,\n",
       "       0.21489429, 0.19321772, 0.21489429, 0.21489429, 0.21489429,\n",
       "       0.21489429, 0.21489429, 0.21489429, 0.21489429, 0.71227322,\n",
       "       0.21489429, 0.21489429, 0.21489429, 0.21489429, 0.21489429,\n",
       "       0.21489429, 0.71227322, 0.24340603, 0.71227322, 0.24340603,\n",
       "       0.21489429, 0.17896185, 0.17896185, 0.71227322, 0.21489429,\n",
       "       0.69059665, 0.21489429, 0.71227322, 0.21489429, 0.74078496,\n",
       "       0.21489429, 0.24340603, 0.21489429, 0.21489429, 0.69059665,\n",
       "       0.21489429, 0.20747359, 0.71227322, 0.74078496, 0.71227322,\n",
       "       0.71227322, 0.24340603, 0.21489429, 0.21489429, 0.71227322,\n",
       "       0.21489429, 0.21489429, 0.21489429, 0.21489429, 0.71227322,\n",
       "       0.21489429, 0.74078496, 0.21489429, 0.24340603, 0.71227322,\n",
       "       0.21489429, 0.21489429, 0.17896185, 0.21489429, 0.17896185,\n",
       "       0.17896185, 0.17896185, 0.72652909, 0.21489429, 0.17896185,\n",
       "       0.21489429, 0.71227322, 0.19321772, 0.21489429, 0.24340603,\n",
       "       0.24340603, 0.24340603, 0.24340603, 0.20747359, 0.71227322,\n",
       "       0.71227322, 0.69059665, 0.21489429, 0.21489429, 0.71227322,\n",
       "       0.20747359, 0.71227322, 0.74078496, 0.71227322, 0.71227322,\n",
       "       0.24340603, 0.17896185, 0.71227322, 0.21489429, 0.21489429,\n",
       "       0.71227322, 0.20747359, 0.21489429, 0.71227322, 0.20747359,\n",
       "       0.71227322, 0.17896185, 0.17896185, 0.71227322, 0.21489429,\n",
       "       0.24340603, 0.71227322, 0.19321772, 0.21489429, 0.21489429,\n",
       "       0.21489429, 0.24340603, 0.71227322, 0.21489429, 0.21489429,\n",
       "       0.19321772, 0.69059665, 0.21489429, 0.71227322, 0.71227322,\n",
       "       0.22915016, 0.22915016, 0.71227322, 0.71227322, 0.74078496,\n",
       "       0.71227322, 0.71227322, 0.22915016, 0.74078496, 0.17896185,\n",
       "       0.17896185, 0.21489429, 0.20747359, 0.21489429, 0.71227322,\n",
       "       0.21489429, 0.17896185, 0.21489429, 0.21489429, 0.21489429,\n",
       "       0.74078496, 0.21489429, 0.21489429, 0.69059665, 0.21489429,\n",
       "       0.21489429, 0.71227322, 0.21489429, 0.22915016, 0.69059665,\n",
       "       0.21489429, 0.71227322, 0.20747359, 0.21489429, 0.74078496,\n",
       "       0.17896185, 0.74078496, 0.71227322, 0.21489429, 0.71227322,\n",
       "       0.74078496, 0.21489429, 0.71227322, 0.17896185, 0.21489429,\n",
       "       0.71227322, 0.21489429, 0.74078496, 0.17896185, 0.24340603,\n",
       "       0.71227322, 0.71227322, 0.22915016, 0.71227322, 0.69059665,\n",
       "       0.21489429, 0.21489429, 0.21489429, 0.71227322, 0.22915016,\n",
       "       0.74078496, 0.21489429, 0.17896185, 0.24340603, 0.21489429,\n",
       "       0.71227322, 0.72652909, 0.21489429, 0.71227322, 0.21489429,\n",
       "       0.21489429, 0.21489429, 0.21489429, 0.24340603, 0.71227322,\n",
       "       0.71227322, 0.71227322, 0.19321772])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pclass     Sex   Age  SibSp Embarked\n",
       "615      2  female  24.0      1        S\n",
       "598      3    male   NaN      0        C\n",
       "161      2  female  40.0      0        S\n",
       "854      2  female  44.0      1        S\n",
       "216      3  female  27.0      0        S"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6954817126212205"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(np.exp(y_test), np.exp(preds), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pclass     Sex   Age  SibSp Embarked\n",
       "770      3    male  24.0      0        S\n",
       "178      2    male  30.0      0        S\n",
       "786      3  female  18.0      0        S\n",
       "159      3    male   NaN      8        S\n",
       "656      3    male   NaN      0        S\n",
       "..     ...     ...   ...    ...      ...\n",
       "693      3    male  25.0      0        C\n",
       "79       3  female  30.0      0        S\n",
       "71       3  female  16.0      5        S\n",
       "503      3  female  37.0      0        S\n",
       "828      3    male   NaN      0        Q\n",
       "\n",
       "[268 rows x 5 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Titanic_pipeline.pkl']"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Guardamos pipeline\n",
    "joblib.dump(Titanic_pipeline, 'Titanic_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Titanic_pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
